{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "\n",
    "# Construct linear hypothesis f = w * x + b\n",
    "def linear_hypothesis(w,x):\n",
    "    f_ = np.dot(x,w)\n",
    "#     f_[f_ >= 0] = 1\n",
    "#     f_[f_ <  0] = -1\n",
    "    return f_\n",
    "\n",
    "#  loss =  (MAX(0, 1- y*f(x)))\n",
    "# y * f >= 1 -> OK\n",
    "# y * f < 1 -> contribute to loss \n",
    "def loss_function(y,f):\n",
    "    loss = 1 - y*f\n",
    "    loss[loss < 0] = 0\n",
    "    loss = np.sum(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def subgrad_des(w,y,x):     \n",
    "    f = linear_hypothesis(w,x)    \n",
    "    y_f = y * f # element-wise multiplication  \n",
    "    y_  = -y * x\n",
    "    y_[np.where(y_f >= 1)[0]] = 0\n",
    "#     y_[y_f >= 1] = 0 # only update f * y < 0 or y_f = -f * y > 0 -> misclassify\n",
    "\n",
    "    b = 1 * y\n",
    "    b[np.where(y_f >= 1)[0]] = 0\n",
    "    \n",
    "    subgrad = np.sum(y_, axis=0)\n",
    "    subgrad[0] = -np.sum(b, axis=0)\n",
    "    return np.array([subgrad])\n",
    "    \n",
    "#     y_= -y * f\n",
    "\n",
    "#     delta = -np.dot(x,y.T)\n",
    "    \n",
    "#     w = w - rate * (lamda * w + delta)\n",
    "#     return w\n",
    "\n",
    "def batch_training(x,y,c,learning_rate,loop_time):\n",
    "    print(\"Batch Training............\")\n",
    "    \n",
    "#     learning_rate = 1\n",
    "    N = x.shape[0]\n",
    "    lamda = 2 / (c * N)\n",
    "    \n",
    "#     w = np.ones((x.shape[1],1)) # Initialize weight = 1    \n",
    "#     w = np.zeros((x.shape[1],1)) # Initialize weight = 0 \n",
    "    w = np.random.rand(x.shape[1],1)\n",
    "    i = 0;\n",
    "    loss = 0;\n",
    "    j = 0;\n",
    "#     while(True):\n",
    "    while(i < loop_time):\n",
    "        print(\"Step \"+ str(i+1)+\": \")\n",
    "#         print(w.T)\n",
    "        f = linear_hypothesis(w,x)\n",
    "        loss = loss_function(y,f)\n",
    "        print(\"Loss = \" + str(loss))\n",
    "        if (loss == 0):\n",
    "            j = j + 1\n",
    "            if (j == 1):                \n",
    "                print(\"Converge\")\n",
    "                print(w.T)\n",
    "                break\n",
    "        # Update Weight\n",
    "#         print(subgrad_des(w,y,x))\n",
    "#         w = w - learning_rate * (c*subgrad_des(w,y,x).T) # with lamda\n",
    "        w = w - learning_rate * (lamda * w + c*subgrad_des(w,y,x).T) # with lamda\n",
    "#         w = w - learning_rate * (w + c * subgrad_des(w,y,x).T) #without lamda\n",
    "        # Compute loss\n",
    "        print(\"----------------\")\n",
    "        i = i + 1\n",
    "    return w\n",
    "\n",
    "def stochastic_training(x,y,c,learning_rate,loop_time):\n",
    "    print(\"Stochastic Training............\")\n",
    "    w = np.zeros((x.shape[1],1)) # Initialize weight = 0\n",
    "    i = 0  \n",
    "    f = linear_hypothesis(w,x)\n",
    "    while(True):\n",
    "        j = 0\n",
    "        for data_point in x:\n",
    "            print(\"Training \"+str(i+1))\n",
    "            f_point = linear_hypothesis(w,data_point)   \n",
    "            f[j] = f_point     \n",
    "            loss = loss_function (y,f)\n",
    "            print(\"Loss = \" + str(loss))\n",
    "            if (loss == 0):\n",
    "                print(\"Converge\")\n",
    "                print(\"Weight: \" +str(w))\n",
    "                return w\n",
    "            \n",
    "            #Update weight\n",
    "            if (f_point * y[j] < 1):\n",
    "                print(\"Misclassify\")\n",
    "                delta = np.array([data_point * y[j]])\n",
    "                w = w - learning_rate * (w - c* delta.T)\n",
    "            else:\n",
    "                w = w - learning_rate * (w)\n",
    "            j = j + 1\n",
    "            i = i + 1 \n",
    "            print(\"---------------\")\n",
    "            if (i == loop_time):\n",
    "                return w\n",
    "\n",
    "def testing(w,x,y):\n",
    "    f = linear_hypothesis(w,x)\n",
    "    f[f >= 0] = 1\n",
    "    f[f <  0] = -1\n",
    "    result = f * y\n",
    "    result[result < 0] = 0\n",
    "    return sum(result) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64967973],\n",
       "       [ 0.33328846],\n",
       "       [ 0.12313569]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.rand(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test loss function\n",
    "w = np.zeros((train_x.shape[1],1)) # Initialize weight = 0   \n",
    "f = linear_hypothesis(w,train_x)\n",
    "loss_function(train_y,f)\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = np.loadtxt(\"wdbc_train.data\", dtype='d', delimiter=',')\n",
    "row_length,col_length = input.shape\n",
    "# print(input)\n",
    "\n",
    "row_training  = int(row_length)\n",
    "training_data = input[0:row_training,0:col_length]\n",
    "\n",
    "# Initialize training\n",
    "train_x = input[:,1:col_length] \n",
    "train_x = np.hstack((np.ones((row_training,1)),train_x)) #Add ones as bias\n",
    "train_y = input[:,0:1]\n",
    "c = 100\n",
    "rate = 0.001\n",
    "loop_time = 2000\n",
    "train_w = batch_training(train_x,train_y,c,rate,loop_time)\n",
    "# train_w = stochastic_training(train_x,train_y,c,rate,loop_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75297619])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing(train_w,train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.47000000e+09],\n",
       "       [ -2.72275271e+10],\n",
       "       [  4.48925730e+10],\n",
       "       [ -1.19598254e+11],\n",
       "       [  1.42515900e+10],\n",
       "       [  2.07483535e+08],\n",
       "       [  1.36271739e+09],\n",
       "       [  2.32787183e+09],\n",
       "       [  1.02035413e+09],\n",
       "       [  1.94585620e+08],\n",
       "       [ -3.46856600e+07]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54117647])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation\n",
    "input_valid = np.loadtxt(\"wdbc_valid.data\", dtype='d', delimiter=',')\n",
    "row_length_valid,col_length_valid = input_valid.shape\n",
    "# print(input)\n",
    "row_valid  = int(row_length_valid)\n",
    "valid_data = input_valid[0:row_length_valid,0:col_length_valid]\n",
    "\n",
    "# Initialize training\n",
    "valid_x = input_valid[:,1:col_length_valid] \n",
    "valid_x = np.hstack((np.ones((row_valid,1)),valid_x)) #Add ones as bias\n",
    "valid_y = input_valid[:,0:1]\n",
    "testing(train_w,valid_x,valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86486486])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "input_test = np.loadtxt(\"wdbc_test.data\", dtype='d', delimiter=',')\n",
    "row_length_test,col_length_test = input_test.shape\n",
    "# print(input)\n",
    "row_test  = int(row_length_test)\n",
    "# test_data = input_test[0:row_length_test,0:col_length_test]\n",
    "\n",
    "# Initialize training\n",
    "test_x = input_test[:,1:col_length_test] \n",
    "test_x = np.hstack((np.ones((row_test,1)),test_x)) #Add ones as bias\n",
    "test_y = input_test[:,0:1]\n",
    "testing(train_w,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196428571428571\n"
     ]
    }
   ],
   "source": [
    "#Learn with Skit-learn\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C=10000000,kernel = 'linear')\n",
    "train_x_ = input[:,1:col_length] \n",
    "# train_x = np.hstack((np.ones((row_length,1)),train_x)) # add zeros as biases\n",
    "train_y_ = input[:,0:1]\n",
    "clf.fit(train_x_,  train_y_.ravel()) \n",
    "\n",
    "#Test on training_set\n",
    "predict = clf.predict(train_x_)\n",
    "count = 0\n",
    "for i in range(0,predict.shape[0]):\n",
    "    if (predict[i] == train_y_[i]):\n",
    "        count = count + 1\n",
    "print (count / row_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4226190476190476\n"
     ]
    }
   ],
   "source": [
    "#Test on test_set\n",
    "test_x_ = input_test[:,1:col_length_test] \n",
    "test_y_ = input_test[:,0:1]\n",
    "predict_test = clf.predict(test_x_)\n",
    "count = 0\n",
    "for i in range(0,predict_test.shape[0]):\n",
    "    if (predict_test[i] == test_y_[i]):\n",
    "        count = count + 1\n",
    "print (count / row_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 1)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quadprop Solver\n",
    "from cvxopt import matrix\n",
    "P = matrix([[1.0,0.0],[0.0,0.0]])\n",
    "q = matrix([3.0,4.0])\n",
    "G = matrix([[-1.0,0.0,-1.0,2.0,3.0],[0.0,-1.0,-3.0,5.0,4.0]])\n",
    "h = matrix([0.0,0.0,-15.0,100.0,80.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0780e+02 -7.6366e+02  9e+02  0e+00  4e+01\n",
      " 1:  9.3245e+01  9.7637e+00  8e+01  6e-17  3e+00\n",
      " 2:  6.7311e+01  3.2553e+01  3e+01  6e-17  1e+00\n",
      " 3:  2.6071e+01  1.5068e+01  1e+01  2e-17  7e-01\n",
      " 4:  3.7092e+01  2.3152e+01  1e+01  5e-18  4e-01\n",
      " 5:  2.5352e+01  1.8652e+01  7e+00  7e-17  3e-16\n",
      " 6:  2.0062e+01  1.9974e+01  9e-02  2e-16  3e-16\n",
      " 7:  2.0001e+01  2.0000e+01  9e-04  8e-17  5e-16\n",
      " 8:  2.0000e+01  2.0000e+01  9e-06  1e-16  2e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "import numpy\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "# Define QP parameters (directly)\n",
    "P = matrix([[1.0,0.0],[0.0,0.0]])\n",
    "q = matrix([3.0,4.0])\n",
    "G = matrix([[-1.0,0.0,-1.0,2.0,3.0],[0.0,-1.0,-3.0,5.0,4.0]])\n",
    "h = matrix([0.0,0.0,-15.0,100.0,80.0])\n",
    "# # Define QP parameters (with NumPy)\n",
    "# P = matrix(numpy.diag([1,0]), tc=’d’)\n",
    "# q = matrix(numpy.array([3,4]), tc=’d’)\n",
    "# G = matrix(numpy.array([[-1,0],[0,-1],[-1,-3],[2,5],[3,4]]), tc=’d’)\n",
    "# h = matrix(numpy.array([0,0,-15,100,80]), tc=’d’)\n",
    "# Construct the QP, invoke solver\n",
    "sol = solvers.qp(P,q,G,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Final version\n",
    "import numpy as np\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "\n",
    "def load_data(filename):\n",
    "    input = np.loadtxt(filename, dtype='d', delimiter=',')\n",
    "    row_length,col_length = input.shape\n",
    "\n",
    "    row_training  = int(row_length) #336\n",
    "    training_data = input[0:row_training,0:col_length]\n",
    "\n",
    "    # Initialize training\n",
    "    train_x = input[:,1:col_length]\n",
    "    train_x = np.concatenate((train_x,np.ones((row_training,1))),axis = 1)#Add ones column as bias\n",
    "    train_y = input[:,0:1]\n",
    "    return [train_x,train_y]\n",
    "    \n",
    "def SVM_primal(filename,c):\n",
    "    # Load input\n",
    "    input = np.loadtxt(filename, dtype='d', delimiter=',')\n",
    "    row_length,col_length = input.shape\n",
    "\n",
    "    row_training  = int(row_length) #336\n",
    "    training_data = input[0:row_training,0:col_length]\n",
    "\n",
    "    # Initialize training\n",
    "    train_x = input[:,1:col_length]\n",
    "    train_x = np.concatenate((train_x,np.ones((row_training,1))),axis = 1)#Add ones column as bias\n",
    "    train_y = input[:,0:1]\n",
    "#     c = 1\n",
    "    feature_num = train_x.shape[1] #11\n",
    "\n",
    "    P = np.eye(feature_num-1)\n",
    "    P = np.concatenate((P,np.zeros((feature_num-1,row_training+1))),axis = 1)\n",
    "    P = np.concatenate((P,np.zeros((row_training+1,row_training+feature_num))),axis = 0) #347 x 347\n",
    "\n",
    "    q = c * np.concatenate((np.zeros((1,feature_num)),train_y.T),axis=1)\n",
    "\n",
    "    h = np.concatenate((-np.ones((row_training,1)),np.zeros((row_training,1))),axis=0)\n",
    "\n",
    "    x = np.concatenate((train_x,np.zeros((row_training,feature_num))),axis=0) #336 x 347\n",
    "    eye = np.eye(row_training) # 336 x 336\n",
    "    eye = np.vstack((eye,eye)) #Add ones column as bias -> already added above\n",
    "    x = np.concatenate((x,eye),axis=1) #672 x 347\n",
    "    y = np.concatenate((train_y,train_y),axis=0)\n",
    "    G = -y * x\n",
    "\n",
    "    # Quadprop for Primal\n",
    "\n",
    "    # Define QP parameters (directly)\n",
    "    P_ = matrix(P)\n",
    "    q_ = matrix(q.T)\n",
    "    G_ = matrix(G)\n",
    "    h_ = matrix(h)\n",
    "\n",
    "    # Construct the QP, invoke solver\n",
    "    sol = solvers.qp(P_,q_,G_,h_)\n",
    "\n",
    "    # Get weight and b\n",
    "    train_w = np.array(sol['x'])\n",
    "    train_w = train_w[0:feature_num]\n",
    "#     f = np.dot(train_x,train_w)\n",
    "#     f[f < 0] = -1\n",
    "#     f[f > 0] =  1 \n",
    "\n",
    "#     #print training accurary\n",
    "#     print (\"Accuracy: \"+str(100*np.count_nonzero(train_y*f+1)/row_training))\n",
    "    return train_w\n",
    "    #print Testing accurary\n",
    "\n",
    "    # np.count_nonzero(train_y*f+1)\n",
    "    \n",
    "def testing(filename,w):\n",
    "    data = load_data(filename)\n",
    "    x = data[0]\n",
    "    y = data[1]\n",
    "    row_training = y.shape[0]\n",
    "    f = np.dot(x,w)\n",
    "    f[f < 0] = -1\n",
    "    f[f > 0] =  1 \n",
    "    accuracy = 100*np.count_nonzero(y*f+1)/row_training\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of i: 0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0357e+02  7.9809e+02  4e+03  4e+00  3e+03\n",
      " 1:  3.5097e+02 -2.7369e+02  9e+02  8e-01  5e+02\n",
      " 2:  1.8387e+02  1.1844e+01  2e+02  1e-01  9e+01\n",
      " 3:  1.0090e+02  6.6064e+01  4e+01  2e-02  1e+01\n",
      " 4:  9.3758e+01  7.3132e+01  2e+01  1e-02  8e+00\n",
      " 5:  8.8163e+01  7.8302e+01  1e+01  4e-03  3e+00\n",
      " 6:  8.5883e+01  8.0141e+01  6e+00  2e-03  1e+00\n",
      " 7:  8.4360e+01  8.1375e+01  3e+00  8e-04  5e-01\n",
      " 8:  8.3596e+01  8.2040e+01  2e+00  2e-04  1e-01\n",
      " 9:  8.3317e+01  8.2249e+01  1e+00  8e-05  5e-02\n",
      "10:  8.2835e+01  8.2647e+01  2e-01  2e-06  2e-03\n",
      "11:  8.2739e+01  8.2732e+01  8e-03  9e-08  6e-05\n",
      "12:  8.2735e+01  8.2735e+01  1e-04  1e-09  9e-07\n",
      "13:  8.2735e+01  8.2735e+01  1e-06  1e-11  4e-08\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "90.17857142857143\n",
      "Testing Accuracy:\n",
      "96.62162162162163\n",
      "Valid Accuracy:\n",
      "91.76470588235294\n",
      "Value of i: 1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6390e+04  2.2442e+04  8e+04  2e+01  1e+03\n",
      " 1:  3.0186e+03 -3.9979e+03  2e+04  4e+00  2e+02\n",
      " 2:  1.8191e+03 -1.1527e+02  3e+03  5e-01  2e+01\n",
      " 3:  1.0616e+03  4.4035e+02  9e+02  1e-01  5e+00\n",
      " 4:  1.1234e+03  4.8875e+02  9e+02  1e-01  4e+00\n",
      " 5:  9.6262e+02  6.0830e+02  4e+02  3e-02  1e+00\n",
      " 6:  9.0075e+02  6.3445e+02  3e+02  2e-02  9e-01\n",
      " 7:  8.9539e+02  6.5010e+02  3e+02  1e-02  6e-01\n",
      " 8:  8.3623e+02  6.7516e+02  2e+02  8e-03  3e-01\n",
      " 9:  8.0804e+02  6.9091e+02  1e+02  5e-03  2e-01\n",
      "10:  7.7620e+02  7.0824e+02  7e+01  2e-03  1e-01\n",
      "11:  7.5340e+02  7.1751e+02  4e+01  4e-15  5e-10\n",
      "12:  7.3566e+02  7.3124e+02  4e+00  3e-15  2e-10\n",
      "13:  7.3343e+02  7.3289e+02  5e-01  3e-15  2e-10\n",
      "14:  7.3314e+02  7.3312e+02  2e-02  3e-15  5e-10\n",
      "15:  7.3313e+02  7.3313e+02  2e-04  2e-15  2e-08\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "91.36904761904762\n",
      "Testing Accuracy:\n",
      "96.62162162162163\n",
      "Valid Accuracy:\n",
      "92.94117647058823\n",
      "Value of i: 2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6987e+06  1.7275e+06  6e+06  2e+02  8e+02\n",
      " 1:  5.3606e+04 -3.2544e+05  1e+06  4e+01  1e+02\n",
      " 2:  8.4542e+04 -3.5652e+04  2e+05  5e+00  2e+01\n",
      " 3:  3.6665e+04 -2.6603e+03  6e+04  1e+00  4e+00\n",
      " 4:  4.1320e+04  2.3884e+02  6e+04  7e-01  3e+00\n",
      " 5:  3.7437e+04  2.2568e+03  4e+04  5e-14  6e-11\n",
      " 6:  2.8769e+04  3.2148e+03  3e+04  3e-14  2e-11\n",
      " 7:  1.3367e+04  4.0496e+03  9e+03  2e-14  8e-11\n",
      " 8:  1.1678e+04  4.4897e+03  7e+03  1e-14  2e-11\n",
      " 9:  9.5465e+03  4.8917e+03  5e+03  6e-15  8e-12\n",
      "10:  7.5988e+03  5.3496e+03  2e+03  4e-15  6e-11\n",
      "11:  7.3228e+03  5.5123e+03  2e+03  3e-15  2e-11\n",
      "12:  6.8966e+03  5.6785e+03  1e+03  4e-15  6e-11\n",
      "13:  6.5071e+03  5.8453e+03  7e+02  3e-15  3e-10\n",
      "14:  6.1814e+03  5.9854e+03  2e+02  3e-15  3e-10\n",
      "15:  6.1130e+03  6.0335e+03  8e+01  2e-15  2e-10\n",
      "16:  6.0769e+03  6.0643e+03  1e+01  2e-15  1e-10\n",
      "17:  6.0703e+03  6.0700e+03  3e-01  3e-15  2e-09\n",
      "18:  6.0702e+03  6.0701e+03  1e-02  2e-15  2e-09\n",
      "19:  6.0701e+03  6.0701e+03  2e-04  3e-15  8e-09\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "93.45238095238095\n",
      "Testing Accuracy:\n",
      "97.97297297297297\n",
      "Valid Accuracy:\n",
      "90.58823529411765\n",
      "Value of i: 3\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7047e+08  1.6764e+08  6e+08  2e+03  8e+02\n",
      " 1:  3.0649e+06 -3.1879e+07  1e+08  4e+02  1e+02\n",
      " 2:  7.5966e+06 -3.8584e+06  2e+07  5e+01  2e+01\n",
      " 3:  3.0137e+06 -6.0806e+05  6e+06  1e+01  3e+00\n",
      " 4:  3.4797e+06 -3.0481e+05  5e+06  6e+00  2e+00\n",
      " 5:  2.6485e+06 -8.9395e+04  3e+06  5e-13  2e-10\n",
      " 6:  1.1059e+06 -2.0972e+04  1e+06  3e-13  8e-11\n",
      " 7:  3.4907e+05  1.4682e+04  3e+05  6e-14  6e-12\n",
      " 8:  1.6171e+05  2.7738e+04  1e+05  2e-14  9e-12\n",
      " 9:  1.5404e+05  3.2812e+04  1e+05  1e-14  6e-12\n",
      "10:  1.1228e+05  3.9066e+04  7e+04  9e-15  2e-11\n",
      "11:  8.1842e+04  4.3764e+04  4e+04  8e-15  3e-11\n",
      "12:  7.8489e+04  4.5658e+04  3e+04  8e-15  3e-11\n",
      "13:  6.9736e+04  4.7936e+04  2e+04  5e-15  2e-10\n",
      "14:  6.2018e+04  5.0204e+04  1e+04  5e-15  5e-10\n",
      "15:  6.0025e+04  5.0835e+04  9e+03  4e-15  3e-10\n",
      "16:  5.7273e+04  5.2313e+04  5e+03  4e-15  8e-11\n",
      "17:  5.5005e+04  5.3541e+04  1e+03  5e-15  1e-10\n",
      "18:  5.4395e+04  5.3957e+04  4e+02  4e-15  9e-11\n",
      "19:  5.4215e+04  5.4098e+04  1e+02  3e-15  1e-09\n",
      "20:  5.4183e+04  5.4126e+04  6e+01  3e-15  4e-10\n",
      "21:  5.4158e+04  5.4149e+04  9e+00  4e-15  3e-10\n",
      "22:  5.4153e+04  5.4153e+04  1e-01  4e-15  5e-09\n",
      "23:  5.4153e+04  5.4153e+04  1e-03  5e-15  6e-09\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "93.1547619047619\n",
      "Testing Accuracy:\n",
      "97.29729729729729\n",
      "Valid Accuracy:\n",
      "90.58823529411765\n",
      "Value of i: 4\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7053e+10  1.6713e+10  6e+10  2e+04  8e+02\n",
      " 1:  2.8407e+08 -3.1813e+09  1e+10  4e+03  1e+02\n",
      " 2:  7.5120e+08 -3.8863e+08  2e+09  5e+02  2e+01\n",
      " 3:  2.9491e+08 -6.4023e+07  6e+08  1e+02  3e+00\n",
      " 4:  3.4161e+08 -3.3186e+07  5e+08  6e+01  2e+00\n",
      " 5:  2.4998e+08 -1.1480e+07  3e+08  4e-12  6e-11\n",
      " 6:  9.8137e+07 -4.8695e+06  1e+08  2e-12  1e-10\n",
      " 7:  5.0521e+07 -1.9902e+06  5e+07  8e-13  7e-11\n",
      " 8:  1.8288e+07 -6.8455e+05  2e+07  3e-13  6e-12\n",
      " 9:  9.3155e+06  5.3162e+04  9e+06  1e-13  8e-11\n",
      "10:  2.4678e+06  2.6468e+05  2e+06  6e-14  9e-12\n",
      "11:  1.3731e+06  3.3316e+05  1e+06  3e-14  4e-11\n",
      "12:  1.0358e+06  3.7931e+05  7e+05  2e-14  3e-11\n",
      "13:  8.4831e+05  4.1013e+05  4e+05  1e-14  1e-10\n",
      "14:  6.9388e+05  4.5138e+05  2e+05  7e-15  8e-11\n",
      "15:  6.4646e+05  4.7192e+05  2e+05  7e-15  5e-11\n",
      "16:  6.0983e+05  4.8285e+05  1e+05  4e-15  2e-10\n",
      "17:  5.7968e+05  4.9421e+05  9e+04  5e-15  3e-10\n",
      "18:  5.5945e+05  5.0327e+05  6e+04  4e-15  4e-10\n",
      "19:  5.4183e+05  5.1146e+05  3e+04  4e-15  6e-10\n",
      "20:  5.3240e+05  5.1667e+05  2e+04  5e-15  3e-10\n",
      "21:  5.2461e+05  5.2150e+05  3e+03  4e-15  1e-10\n",
      "22:  5.2359e+05  5.2226e+05  1e+03  4e-15  5e-10\n",
      "23:  5.2297e+05  5.2273e+05  2e+02  4e-15  3e-09\n",
      "24:  5.2285e+05  5.2284e+05  3e+00  4e-15  5e-09\n",
      "25:  5.2284e+05  5.2284e+05  3e-02  5e-15  6e-10\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "93.45238095238095\n",
      "Testing Accuracy:\n",
      "97.29729729729729\n",
      "Valid Accuracy:\n",
      "89.41176470588235\n",
      "Value of i: 5\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7053e+12  1.6708e+12  6e+12  2e+05  8e+02\n",
      " 1:  2.8183e+10 -3.1806e+11  1e+12  4e+04  1e+02\n",
      " 2:  7.5036e+10 -3.8891e+10  2e+11  5e+03  2e+01\n",
      " 3:  2.9426e+10 -6.4343e+09  6e+10  1e+03  3e+00\n",
      " 4:  3.4097e+10 -3.3448e+09  5e+10  6e+02  2e+00\n",
      " 5:  2.4842e+10 -1.1727e+09  3e+10  5e-11  2e-10\n",
      " 6:  9.6681e+09 -5.1307e+08  1e+10  2e-11  1e-11\n",
      " 7:  5.2415e+09 -2.3469e+08  5e+09  8e-12  3e-11\n",
      " 8:  1.8961e+09 -1.0141e+08  2e+09  4e-12  3e-12\n",
      " 9:  9.8243e+08 -2.2917e+07  1e+09  1e-12  3e-11\n",
      "10:  2.1727e+08 -9.2443e+05  2e+08  7e-13  8e-11\n",
      "11:  5.8678e+07  2.5479e+06  6e+07  2e-13  1e-11\n",
      "12:  2.3956e+07  2.9672e+06  2e+07  7e-14  3e-11\n",
      "13:  1.5355e+07  3.4005e+06  1e+07  3e-14  2e-10\n",
      "14:  1.0845e+07  3.8153e+06  7e+06  2e-14  6e-11\n",
      "15:  8.2658e+06  4.1278e+06  4e+06  1e-14  1e-10\n",
      "16:  7.5031e+06  4.3535e+06  3e+06  9e-15  3e-11\n",
      "17:  6.8365e+06  4.5715e+06  2e+06  9e-15  3e-11\n",
      "18:  6.5021e+06  4.6608e+06  2e+06  7e-15  1e-10\n",
      "19:  5.9564e+06  4.8250e+06  1e+06  4e-15  7e-11\n",
      "20:  5.7134e+06  4.9632e+06  8e+05  4e-15  4e-11\n",
      "21:  5.5320e+06  4.9949e+06  5e+05  7e-15  5e-10\n",
      "22:  5.4121e+06  5.0578e+06  4e+05  3e-15  1e-10\n",
      "23:  5.2837e+06  5.1335e+06  2e+05  3e-15  4e-10\n",
      "24:  5.2193e+06  5.1733e+06  5e+04  4e-15  6e-11\n",
      "25:  5.1986e+06  5.1913e+06  7e+03  3e-15  2e-10\n",
      "26:  5.1948e+06  5.1947e+06  8e+01  4e-15  2e-10\n",
      "27:  5.1947e+06  5.1947e+06  8e-01  5e-15  8e-12\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "93.45238095238095\n",
      "Testing Accuracy:\n",
      "97.29729729729729\n",
      "Valid Accuracy:\n",
      "89.41176470588235\n",
      "Value of i: 6\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7053e+14  1.6708e+14  6e+14  2e+06  8e+02\n",
      " 1:  2.8161e+12 -3.1805e+13  1e+14  4e+05  1e+02\n",
      " 2:  7.5027e+12 -3.8894e+12  2e+13  5e+04  2e+01\n",
      " 3:  2.9420e+12 -6.4374e+11  6e+12  1e+04  3e+00\n",
      " 4:  3.4091e+12 -3.3475e+11  5e+12  6e+03  2e+00\n",
      " 5:  2.4826e+12 -1.1751e+11  3e+12  5e-10  8e-11\n",
      " 6:  9.6534e+11 -5.1567e+10  1e+12  2e-10  1e-10\n",
      " 7:  5.2596e+11 -2.3823e+10  5e+11  9e-11  5e-11\n",
      " 8:  1.9026e+11 -1.0465e+10  2e+11  3e-11  2e-10\n",
      " 9:  9.8743e+10 -2.5640e+09  1e+11  1e-11  4e-11\n",
      "10:  2.1455e+10 -3.4736e+08  2e+10  7e-12  3e-11\n",
      "11:  5.3476e+09 -2.2311e+06  5e+09  2e-12  1e-10\n",
      "12:  7.4378e+08  2.5783e+07  7e+08  5e-13  4e-11\n",
      "13:  2.5917e+08  3.0361e+07  2e+08  9e-14  4e-11\n",
      "14:  1.2725e+08  3.4235e+07  9e+07  3e-14  2e-10\n",
      "15:  1.1297e+08  3.8424e+07  7e+07  2e-14  1e-10\n",
      "16:  8.2854e+07  4.1092e+07  4e+07  1e-14  4e-11\n",
      "17:  7.6228e+07  4.3239e+07  3e+07  1e-14  9e-12\n",
      "18:  6.7813e+07  4.5533e+07  2e+07  6e-15  9e-11\n",
      "19:  6.3665e+07  4.6824e+07  2e+07  5e-15  7e-11\n",
      "20:  6.1637e+07  4.7665e+07  1e+07  6e-15  3e-11\n",
      "21:  5.9157e+07  4.8657e+07  1e+07  5e-15  1e-10\n",
      "22:  5.6103e+07  5.0075e+07  6e+06  4e-15  2e-10\n",
      "23:  5.5147e+07  5.0173e+07  5e+06  3e-15  2e-10\n",
      "24:  5.3806e+07  5.0772e+07  3e+06  3e-15  2e-10\n",
      "25:  5.3249e+07  5.0964e+07  2e+06  3e-15  9e-11\n",
      "26:  5.2229e+07  5.1650e+07  6e+05  4e-15  1e-10\n",
      "27:  5.1982e+07  5.1852e+07  1e+05  4e-15  3e-11\n",
      "28:  5.1911e+07  5.1909e+07  2e+03  4e-15  1e-10\n",
      "29:  5.1910e+07  5.1910e+07  2e+01  5e-15  5e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "93.45238095238095\n",
      "Testing Accuracy:\n",
      "97.29729729729729\n",
      "Valid Accuracy:\n",
      "89.41176470588235\n",
      "Value of i: 7\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7053e+16  1.6708e+16  6e+16  2e+07  8e+02\n",
      " 1:  2.8158e+14 -3.1805e+15  1e+16  4e+06  1e+02\n",
      " 2:  7.5026e+14 -3.8894e+14  2e+15  5e+05  2e+01\n",
      " 3:  2.9419e+14 -6.4378e+13  6e+14  1e+05  3e+00\n",
      " 4:  3.4090e+14 -3.3477e+13  5e+14  6e+04  2e+00\n",
      " 5:  2.4824e+14 -1.1754e+13  3e+14  4e-09  1e-10\n",
      " 6:  9.6519e+13 -5.1593e+12  1e+14  2e-09  8e-11\n",
      " 7:  5.2614e+13 -2.3858e+12  5e+13  8e-10  9e-12\n",
      " 8:  1.9032e+13 -1.0497e+12  2e+13  4e-10  8e-12\n",
      " 9:  9.8793e+12 -2.5912e+11  1e+13  1e-10  1e-10\n",
      "10:  2.1428e+12 -3.7268e+10  2e+12  7e-11  8e-11\n",
      "11:  5.2976e+11 -2.7312e+09  5e+11  2e-11  8e-11\n",
      "12:  7.7119e+10  3.5304e+07  8e+10  6e-12  9e-11\n",
      "13:  9.7150e+09  2.7798e+08  9e+09  1e-12  4e-11\n",
      "14:  2.1334e+09  2.9126e+08  2e+09  2e-13  2e-11\n",
      "15:  1.4588e+09  3.3790e+08  1e+09  1e-13  4e-11\n",
      "16:  1.1333e+09  3.7734e+08  8e+08  6e-14  2e-10\n",
      "17:  7.8992e+08  4.1289e+08  4e+08  3e-14  2e-10\n",
      "18:  7.5117e+08  4.3421e+08  3e+08  2e-14  3e-10\n",
      "19:  6.7545e+08  4.5397e+08  2e+08  2e-14  7e-11\n",
      "20:  6.3840e+08  4.6703e+08  2e+08  1e-14  2e-10\n",
      "21:  6.1205e+08  4.7802e+08  1e+08  7e-15  1e-10\n",
      "22:  5.7218e+08  4.9404e+08  8e+07  7e-15  7e-11\n",
      "23:  5.5296e+08  5.0275e+08  5e+07  7e-15  2e-10\n",
      "24:  5.4023e+08  5.0644e+08  3e+07  4e-15  1e-10\n",
      "25:  5.3724e+08  5.0808e+08  3e+07  3e-15  8e-11\n",
      "26:  5.2404e+08  5.1565e+08  8e+06  3e-15  6e-11\n",
      "27:  5.2056e+08  5.1795e+08  3e+06  4e-15  7e-11\n",
      "28:  5.1909e+08  5.1904e+08  6e+04  5e-15  4e-10\n",
      "29:  5.1906e+08  5.1906e+08  6e+02  5e-15  3e-10\n",
      "30:  5.1906e+08  5.1906e+08  6e+00  4e-15  2e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "93.45238095238095\n",
      "Testing Accuracy:\n",
      "97.29729729729729\n",
      "Valid Accuracy:\n",
      "89.41176470588235\n",
      "Value of i: 8\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7053e+18  1.6708e+18  6e+18  2e+08  8e+02\n",
      " 1:  2.8158e+16 -3.1805e+17  1e+18  4e+07  1e+02\n",
      " 2:  7.5026e+16 -3.8894e+16  2e+17  5e+06  2e+01\n",
      " 3:  2.9419e+16 -6.4378e+15  6e+16  1e+06  3e+00\n",
      " 4:  3.4090e+16 -3.3477e+15  5e+16  6e+05  2e+00\n",
      " 5:  2.4824e+16 -1.1754e+15  3e+16  4e-08  9e-11\n",
      " 6:  9.6517e+15 -5.1595e+14  1e+16  2e-08  2e-11\n",
      " 7:  5.2615e+15 -2.3862e+14  6e+15  8e-09  1e-11\n",
      " 8:  1.9033e+15 -1.0501e+14  2e+15  3e-09  3e-11\n",
      " 9:  9.8798e+14 -2.5939e+13  1e+15  1e-09  6e-11\n",
      "10:  2.1425e+14 -3.7521e+12  2e+14  6e-10  3e-11\n",
      "11:  5.2926e+13 -2.9814e+11  5e+13  2e-10  2e-10\n",
      "12:  7.7399e+12 -2.1657e+10  8e+12  5e-11  5e-11\n",
      "13:  9.4836e+11  2.6010e+09  9e+11  9e-12  1e-10\n",
      "14:  3.4079e+10  2.7929e+09  3e+10  9e-13  1e-10\n",
      "15:  1.4592e+10  3.2162e+09  1e+10  2e-13  7e-11\n",
      "16:  1.0880e+10  3.6955e+09  7e+09  1e-13  5e-10\n",
      "17:  8.8012e+09  4.0020e+09  5e+09  6e-14  4e-10\n",
      "18:  7.6863e+09  4.2488e+09  3e+09  4e-14  2e-10\n",
      "19:  6.9236e+09  4.4802e+09  2e+09  2e-14  3e-11\n",
      "20:  6.5649e+09  4.6352e+09  2e+09  2e-14  6e-11\n",
      "21:  6.1192e+09  4.7760e+09  1e+09  9e-15  1e-10\n",
      "22:  5.7162e+09  4.9563e+09  8e+08  6e-15  6e-11\n",
      "23:  5.5456e+09  5.0311e+09  5e+08  4e-15  1e-10\n",
      "24:  5.3993e+09  5.0622e+09  3e+08  5e-15  2e-10\n",
      "25:  5.3700e+09  5.0764e+09  3e+08  5e-15  1e-10\n",
      "26:  5.2593e+09  5.1390e+09  1e+08  4e-15  6e-11\n",
      "27:  5.2081e+09  5.1769e+09  3e+07  4e-15  9e-10\n",
      "28:  5.1914e+09  5.1899e+09  2e+06  4e-15  4e-10\n",
      "29:  5.1906e+09  5.1906e+09  2e+04  5e-15  3e-11\n",
      "30:  5.1906e+09  5.1906e+09  2e+02  5e-15  1e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy:\n",
      "93.45238095238095\n",
      "Testing Accuracy:\n",
      "97.29729729729729\n",
      "Valid Accuracy:\n",
      "89.41176470588235\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    c = pow(10,i)\n",
    "    print (\"Value of i: \"+str(i))\n",
    "    w = SVM_primal(\"wdbc_train.data\",c)\n",
    "    print(\"Training Accuracy:\")\n",
    "    print(testing(\"wdbc_train.data\",w))\n",
    "    print(\"Testing Accuracy:\")\n",
    "    print(testing(\"wdbc_test.data\",w))\n",
    "    print(\"Valid Accuracy:\")\n",
    "    print(testing(\"wdbc_valid.data\",w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input = np.loadtxt(\"wdbc_train.data\", dtype='d', delimiter=',')\n",
    "row_length,col_length = input.shape\n",
    "# print(input)\n",
    "\n",
    "row_training  = int(row_length) #336\n",
    "training_data = input[0:row_training,0:col_length]\n",
    "\n",
    "# Initialize training\n",
    "train_x = input[:,1:col_length]\n",
    "train_x = np.concatenate((train_x,np.ones((row_training,1))),axis = 1)#Add ones column as bias\n",
    "# train_x = np.hstack((np.ones((row_training,1)),train_x)) #Add ones column as bias\n",
    "# train_x = np.hstack((np.ones((row_training,1)),train_x)) #Add ones column as E\n",
    "train_y = input[:,0:1]\n",
    "# c = 100\n",
    "feature_num = train_x.shape[1] #11\n",
    "w = np.zeros((feature_num,1)) # Initialize weight = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# w: 10 + 1 + 336\n",
    "# P = np.eye(feature_num-1)\n",
    "\n",
    "P = np.eye(feature_num-1)\n",
    "P = np.concatenate((P,np.zeros((feature_num-1,row_training+1))),axis = 1)\n",
    "P = np.concatenate((P,np.zeros((row_training+1,row_training+feature_num))),axis = 0) #347 x 347\n",
    "\n",
    "# q = c * np.concatenate((np.zeros((1,feature_num)),np.ones((1,row_training))),axis=1)\n",
    "c = 1\n",
    "q = c * np.concatenate((np.zeros((1,feature_num)),train_y.T),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347, 347)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = np.concatenate((-np.ones((row_training,1)),np.zeros((row_training,1))),axis=0)\n",
    "# h.shape\n",
    "# x = np.hstack((np.ones((row_training,row_training)),train_x)) #Add ones column as bias -> already added above\n",
    "# x = np.concatenate((train_x,np.ones((row_training,row_training))),axis=1) #336 x 347\n",
    "x = np.concatenate((train_x,np.zeros((row_training,feature_num))),axis=0) #336 x 347\n",
    "# zero = np.zeros((row_training,feature_num)) # 336 x 11\n",
    "eye = np.eye(row_training) # 336 x 336\n",
    "eye = np.vstack((eye,eye)) #Add ones column as bias -> already added above\n",
    "# eye_ = np.concatenate((eye,np.eye(row_training)),axis=0) #336 x 347\n",
    "x = np.concatenate((x,eye),axis=1) #672 x 347\n",
    "\n",
    "\n",
    "# y = np.concatenate((train_y,np.ones((row_training,1))),axis=0)\n",
    "y = np.concatenate((train_y,train_y),axis=0)\n",
    "G = -y * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,336):\n",
    "    print (x[i+336][i+11])\n",
    "# eye[338][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,336):\n",
    "    print (eye[i+336][i])\n",
    "# eye[338][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 336)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 336)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0357e+02  7.9809e+02  4e+03  4e+00  3e+03\n",
      " 1:  3.5097e+02 -2.7369e+02  9e+02  8e-01  5e+02\n",
      " 2:  1.8387e+02  1.1844e+01  2e+02  1e-01  9e+01\n",
      " 3:  1.0090e+02  6.6064e+01  4e+01  2e-02  1e+01\n",
      " 4:  9.3758e+01  7.3132e+01  2e+01  1e-02  8e+00\n",
      " 5:  8.8163e+01  7.8302e+01  1e+01  4e-03  3e+00\n",
      " 6:  8.5883e+01  8.0141e+01  6e+00  2e-03  1e+00\n",
      " 7:  8.4360e+01  8.1375e+01  3e+00  8e-04  5e-01\n",
      " 8:  8.3596e+01  8.2040e+01  2e+00  2e-04  1e-01\n",
      " 9:  8.3317e+01  8.2249e+01  1e+00  8e-05  5e-02\n",
      "10:  8.2835e+01  8.2647e+01  2e-01  2e-06  2e-03\n",
      "11:  8.2739e+01  8.2732e+01  8e-03  9e-08  6e-05\n",
      "12:  8.2735e+01  8.2735e+01  1e-04  1e-09  9e-07\n",
      "13:  8.2735e+01  8.2735e+01  1e-06  1e-11  4e-08\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "# Define QP parameters (directly)\n",
    "P_ = matrix(P)\n",
    "q_ = matrix(q.T)\n",
    "G_ = matrix(G)\n",
    "h_ = matrix(h)\n",
    "\n",
    "# Construct the QP, invoke solver\n",
    "sol = solvers.qp(P_,q_,G_,h_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.54581202e+00],\n",
       "       [  1.28495106e-01],\n",
       "       [  2.56166825e-01],\n",
       "       [  3.88447753e-03],\n",
       "       [  5.41083024e-01],\n",
       "       [  6.53573268e-01],\n",
       "       [  1.42764308e+00],\n",
       "       [  8.04871617e-01],\n",
       "       [  8.11652415e-01],\n",
       "       [  9.88788985e-02],\n",
       "       [ -7.33069113e+00]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w = np.array(sol['x'])\n",
    "train_w = train_w[0:feature_num]\n",
    "train_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 11)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "train_w = np.array(sol['x'])\n",
    "train_w = train_w[0:feature_num]\n",
    "f = np.dot(train_x,train_w)\n",
    "f[f < 0] = -1\n",
    "f[f > 0] =  1 \n",
    "np.count_nonzero(train_y*f+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6155338298766336"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol['x'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.12500000e+01,   1.47800000e+01,   7.13800000e+01,\n",
       "         3.90000000e+02,   8.30600000e-02,   4.45800000e-02,\n",
       "         9.73700000e-04,   2.94100000e-03,   1.77300000e-01,\n",
       "         6.08100000e-02,   1.00000000e+00])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.40e-06]\n",
      "[ 4.85e-08]\n",
      "[ 1.34e-06]\n",
      "[ 1.33e-08]\n",
      "[ 2.58e-05]\n",
      "[ 7.66e-06]\n",
      "[-1.87e-05]\n",
      "[-1.28e-05]\n",
      "[-5.58e-06]\n",
      "[-4.56e-05]\n",
      "[ 2.07e+02]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "[-6.16e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_w = np.array(sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13321774.49463832])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_w[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2068.1934043283895"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol['primal objective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([[-1.5458,0.1285,0.2562,0.0039,0.5411,0.6536,1.4276,0.8049,0.8117,0.0989,-7.3307]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (336,11) and (1,11) not aligned: 11 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-844374e87e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m<\u001b[0m  \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (336,11) and (1,11) not aligned: 11 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "f = np.dot(train_x,train_w.T)\n",
    "f[f >= 0] = 1\n",
    "f[f <  0] = -1\n",
    "np.count_nonzero(train_y*f+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train_y-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Final version dual\n",
    "import numpy as np\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "def load_data(filename):\n",
    "    input = np.loadtxt(filename, dtype='d', delimiter=',')\n",
    "    row_length,col_length = input.shape\n",
    "\n",
    "    row_training  = int(row_length) #336\n",
    "    training_data = input[0:row_training,0:col_length]\n",
    "\n",
    "    # Initialize training\n",
    "    train_x = input[:,1:col_length]\n",
    "#     train_x = np.concatenate((train_x,np.ones((row_training,1))),axis = 1)#Add ones column as bias\n",
    "    train_y = input[:,0:1]\n",
    "    return [train_x,train_y]\n",
    "\n",
    "# from scipy.spatial.distance import pdist, squareform\n",
    "# import scipy as sc\n",
    "# def kernel_gau(x,s):\n",
    "#     pairwise_dists = squareform(pdist(x, 'euclidean'))\n",
    "#     K = sc.exp(-pairwise_dists ** 2 / s ** 2)\n",
    "#     return K\n",
    "\n",
    "def gausian_k(x,z,s):    \n",
    "    k = np.array([]).reshape(0,z.shape[0])\n",
    "    for row_x in x:\n",
    "        temp = np.power(z-row_x,2)\n",
    "        temp = -np.sum(temp,axis=1) / (2 * s * s)\n",
    "        temp = np.exp(temp)\n",
    "        k    = np.vstack([k, temp.T]) \n",
    "    return k\n",
    "\n",
    "def SVM_dual(filename,s,c):\n",
    "    train_x , train_y = load_data(filename)\n",
    "    row_length,col_length = train_x.shape\n",
    "    # k = np.dot(train_x,train_x.T)\n",
    "#     s = 1\n",
    "    k = kernel_gau(train_x,1)\n",
    "    P = k\n",
    "    q = -np.ones((row_length,1))\n",
    "    A = train_y.T\n",
    "    B = np.zeros(1)\n",
    "    G = np.eye(row_length)\n",
    "#     c = 1\n",
    "    h = c*np.ones((row_length,1))\n",
    "\n",
    "    P_ = matrix(P)\n",
    "    q_ = matrix(q)\n",
    "    G_ = matrix(G)\n",
    "    h_ = matrix(h)\n",
    "    A_ = matrix(A)\n",
    "    B_  = matrix(B)\n",
    "    # Construct the QP, invoke solver\n",
    "    sol = solvers.qp(P_,q_,G_,h_,A_,B_)\n",
    "    alpha = np.array(sol['x'])\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = 0.1 c = 10^0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5696e+02 -1.6916e+02  6e+02  1e+00  2e+00\n",
      " 1: -1.1497e+02 -2.0277e+02  9e+01  6e-15  2e-16\n",
      " 2: -1.4801e+02 -1.5891e+02  1e+01  4e-15  1e-16\n",
      " 3: -1.5220e+02 -1.5260e+02  4e-01  9e-16  9e-17\n",
      " 4: -1.5236e+02 -1.5236e+02  4e-03  5e-15  7e-17\n",
      " 5: -1.5236e+02 -1.5236e+02  4e-05  6e-15  7e-17\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.0782e+03 -1.9855e+03  5e+03  4e-14  8e+00\n",
      " 1:  1.3239e+01 -5.4460e+02  6e+02  9e-14  1e+00\n",
      " 2: -1.5707e+02 -1.7498e+02  2e+01  3e-14  2e-02\n",
      " 3: -1.5708e+02 -1.5726e+02  2e-01  4e-15  2e-04\n",
      " 4: -1.5708e+02 -1.5708e+02  2e-03  1e-14  2e-06\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-05  4e-16  2e-08\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9016e+05  2.0973e+04  4e+05  6e-13  8e+01\n",
      " 1:  3.4497e+03 -1.2867e+05  1e+05  1e-13  1e+01\n",
      " 2: -1.5650e+02 -1.7543e+03  2e+03  5e-13  1e-01\n",
      " 3: -1.5708e+02 -1.7307e+02  2e+01  7e-15  1e-03\n",
      " 4: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-05\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-07\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-09\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^3\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9734e+07  4.3627e+06  4e+07  7e-12  8e+02\n",
      " 1:  2.6252e+05 -1.3813e+07  1e+07  6e-12  1e+02\n",
      " 2: -1.1164e+02 -1.5972e+05  2e+05  4e-12  1e+00\n",
      " 3: -1.5707e+02 -1.7542e+03  2e+03  7e-15  1e-02\n",
      " 4: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-04\n",
      " 5: -1.5708e+02 -1.5724e+02  2e-01  5e-15  1e-06\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-03  2e-15  1e-08\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-05  6e-15  1e-10\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^4\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9804e+09  4.5899e+08  4e+09  4e-11  8e+03\n",
      " 1:  2.5351e+07 -1.3909e+09  1e+09  9e-11  1e+03\n",
      " 2:  4.2627e+03 -1.5963e+07  2e+07  2e-12  1e+01\n",
      " 3: -1.5663e+02 -1.5994e+05  2e+05  5e-14  1e-01\n",
      " 4: -1.5708e+02 -1.7549e+03  2e+03  4e-15  1e-03\n",
      " 5: -1.5708e+02 -1.7305e+02  2e+01  2e-16  1e-05\n",
      " 6: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-07\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-03  6e-15  1e-09\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^5\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+11  4.6127e+10  4e+11  4e-11  8e+04\n",
      " 1:  2.5260e+09 -1.3918e+11  1e+11  3e-10  1e+04\n",
      " 2:  4.4057e+05 -1.5964e+09  2e+09  1e-10  1e+02\n",
      " 3: -1.1300e+02 -1.5979e+07  2e+07  6e-12  1e+00\n",
      " 4: -1.5707e+02 -1.5995e+05  2e+05  7e-14  1e-02\n",
      " 5: -1.5708e+02 -1.7550e+03  2e+03  7e-16  1e-04\n",
      " 6: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-06\n",
      " 7: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-08\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-03  2e-16  1e-10\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-12\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^6\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+13  4.6149e+12  4e+13  1e-08  8e+05\n",
      " 1:  2.5251e+11 -1.3919e+13  1e+13  1e-08  1e+05\n",
      " 2:  4.4060e+07 -1.5964e+11  2e+11  7e-09  1e+03\n",
      " 3:  4.2494e+03 -1.5979e+09  2e+09  1e-10  1e+01\n",
      " 4: -1.5664e+02 -1.5979e+07  2e+07  2e-12  1e-01\n",
      " 5: -1.5708e+02 -1.5995e+05  2e+05  5e-15  1e-03\n",
      " 6: -1.5708e+02 -1.7550e+03  2e+03  2e-14  1e-05\n",
      " 7: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-07\n",
      " 8: -1.5708e+02 -1.5724e+02  2e-01  9e-15  1e-09\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-11\n",
      "10: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-13\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^7\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+15  4.6152e+14  4e+15  1e-07  8e+06\n",
      " 1:  2.5250e+13 -1.3920e+15  1e+15  5e-08  1e+06\n",
      " 2:  4.4059e+09 -1.5964e+13  2e+13  4e-08  1e+04\n",
      " 3:  4.4048e+05 -1.5979e+11  2e+11  1e-09  1e+02\n",
      " 4: -1.1301e+02 -1.5979e+09  2e+09  8e-12  1e+00\n",
      " 5: -1.5707e+02 -1.5979e+07  2e+07  7e-14  1e-02\n",
      " 6: -1.5708e+02 -1.5995e+05  2e+05  2e-15  1e-04\n",
      " 7: -1.5708e+02 -1.7550e+03  2e+03  2e-16  1e-06\n",
      " 8: -1.5708e+02 -1.7305e+02  2e+01  2e-15  1e-08\n",
      " 9: -1.5708e+02 -1.5724e+02  2e-01  2e-15  1e-10\n",
      "10: -1.5708e+02 -1.5708e+02  2e-03  7e-15  1e-12\n",
      "11: -1.5708e+02 -1.5708e+02  2e-05  1e-14  1e-14\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 0.1 c = 10^8\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+17  4.6152e+16  4e+17  2e-07  8e+07\n",
      " 1:  2.5250e+15 -1.3920e+17  1e+17  1e-06  1e+07\n",
      " 2:  4.4059e+11 -1.5964e+15  2e+15  1e-07  1e+05\n",
      " 3:  4.4063e+07 -1.5979e+13  2e+13  1e-10  1e+03\n",
      " 4:  4.2492e+03 -1.5979e+11  2e+11  7e-11  1e+01\n",
      " 5: -1.5664e+02 -1.5979e+09  2e+09  5e-13  1e-01\n",
      " 6: -1.5708e+02 -1.5979e+07  2e+07  2e-15  1e-03\n",
      " 7: -1.5708e+02 -1.5995e+05  2e+05  6e-15  1e-05\n",
      " 8: -1.5708e+02 -1.7550e+03  2e+03  3e-15  1e-07\n",
      " 9: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-09\n",
      "10: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-11\n",
      "11: -1.5708e+02 -1.5708e+02  2e-03  1e-14  1e-13\n",
      "12: -1.5708e+02 -1.5708e+02  2e-05  2e-14  1e-15\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "100.0\n",
      "Testing Accuracy\n",
      "93.91891891891892\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "----------------------------------------------------------------\n",
      "s = 1.0 c = 10^0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5696e+02 -1.6916e+02  6e+02  1e+00  2e+00\n",
      " 1: -1.1497e+02 -2.0277e+02  9e+01  6e-15  2e-16\n",
      " 2: -1.4801e+02 -1.5891e+02  1e+01  4e-15  1e-16\n",
      " 3: -1.5220e+02 -1.5260e+02  4e-01  9e-16  9e-17\n",
      " 4: -1.5236e+02 -1.5236e+02  4e-03  5e-15  7e-17\n",
      " 5: -1.5236e+02 -1.5236e+02  4e-05  6e-15  7e-17\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.4047619047619\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.0782e+03 -1.9855e+03  5e+03  4e-14  8e+00\n",
      " 1:  1.3239e+01 -5.4460e+02  6e+02  9e-14  1e+00\n",
      " 2: -1.5707e+02 -1.7498e+02  2e+01  3e-14  2e-02\n",
      " 3: -1.5708e+02 -1.5726e+02  2e-01  4e-15  2e-04\n",
      " 4: -1.5708e+02 -1.5708e+02  2e-03  1e-14  2e-06\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-05  4e-16  2e-08\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9016e+05  2.0973e+04  4e+05  6e-13  8e+01\n",
      " 1:  3.4497e+03 -1.2867e+05  1e+05  1e-13  1e+01\n",
      " 2: -1.5650e+02 -1.7543e+03  2e+03  5e-13  1e-01\n",
      " 3: -1.5708e+02 -1.7307e+02  2e+01  7e-15  1e-03\n",
      " 4: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-05\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-07\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-09\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^3\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9734e+07  4.3627e+06  4e+07  7e-12  8e+02\n",
      " 1:  2.6252e+05 -1.3813e+07  1e+07  6e-12  1e+02\n",
      " 2: -1.1164e+02 -1.5972e+05  2e+05  4e-12  1e+00\n",
      " 3: -1.5707e+02 -1.7542e+03  2e+03  7e-15  1e-02\n",
      " 4: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-04\n",
      " 5: -1.5708e+02 -1.5724e+02  2e-01  5e-15  1e-06\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-03  2e-15  1e-08\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-05  6e-15  1e-10\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^4\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9804e+09  4.5899e+08  4e+09  4e-11  8e+03\n",
      " 1:  2.5351e+07 -1.3909e+09  1e+09  9e-11  1e+03\n",
      " 2:  4.2627e+03 -1.5963e+07  2e+07  2e-12  1e+01\n",
      " 3: -1.5663e+02 -1.5994e+05  2e+05  5e-14  1e-01\n",
      " 4: -1.5708e+02 -1.7549e+03  2e+03  4e-15  1e-03\n",
      " 5: -1.5708e+02 -1.7305e+02  2e+01  2e-16  1e-05\n",
      " 6: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-07\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-03  6e-15  1e-09\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^5\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+11  4.6127e+10  4e+11  4e-11  8e+04\n",
      " 1:  2.5260e+09 -1.3918e+11  1e+11  3e-10  1e+04\n",
      " 2:  4.4057e+05 -1.5964e+09  2e+09  1e-10  1e+02\n",
      " 3: -1.1300e+02 -1.5979e+07  2e+07  6e-12  1e+00\n",
      " 4: -1.5707e+02 -1.5995e+05  2e+05  7e-14  1e-02\n",
      " 5: -1.5708e+02 -1.7550e+03  2e+03  7e-16  1e-04\n",
      " 6: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-06\n",
      " 7: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-08\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-03  2e-16  1e-10\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-12\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^6\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+13  4.6149e+12  4e+13  1e-08  8e+05\n",
      " 1:  2.5251e+11 -1.3919e+13  1e+13  1e-08  1e+05\n",
      " 2:  4.4060e+07 -1.5964e+11  2e+11  7e-09  1e+03\n",
      " 3:  4.2494e+03 -1.5979e+09  2e+09  1e-10  1e+01\n",
      " 4: -1.5664e+02 -1.5979e+07  2e+07  2e-12  1e-01\n",
      " 5: -1.5708e+02 -1.5995e+05  2e+05  5e-15  1e-03\n",
      " 6: -1.5708e+02 -1.7550e+03  2e+03  2e-14  1e-05\n",
      " 7: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-07\n",
      " 8: -1.5708e+02 -1.5724e+02  2e-01  9e-15  1e-09\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-11\n",
      "10: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-13\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^7\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+15  4.6152e+14  4e+15  1e-07  8e+06\n",
      " 1:  2.5250e+13 -1.3920e+15  1e+15  5e-08  1e+06\n",
      " 2:  4.4059e+09 -1.5964e+13  2e+13  4e-08  1e+04\n",
      " 3:  4.4048e+05 -1.5979e+11  2e+11  1e-09  1e+02\n",
      " 4: -1.1301e+02 -1.5979e+09  2e+09  8e-12  1e+00\n",
      " 5: -1.5707e+02 -1.5979e+07  2e+07  7e-14  1e-02\n",
      " 6: -1.5708e+02 -1.5995e+05  2e+05  2e-15  1e-04\n",
      " 7: -1.5708e+02 -1.7550e+03  2e+03  2e-16  1e-06\n",
      " 8: -1.5708e+02 -1.7305e+02  2e+01  2e-15  1e-08\n",
      " 9: -1.5708e+02 -1.5724e+02  2e-01  2e-15  1e-10\n",
      "10: -1.5708e+02 -1.5708e+02  2e-03  7e-15  1e-12\n",
      "11: -1.5708e+02 -1.5708e+02  2e-05  1e-14  1e-14\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "s = 1.0 c = 10^8\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+17  4.6152e+16  4e+17  2e-07  8e+07\n",
      " 1:  2.5250e+15 -1.3920e+17  1e+17  1e-06  1e+07\n",
      " 2:  4.4059e+11 -1.5964e+15  2e+15  1e-07  1e+05\n",
      " 3:  4.4063e+07 -1.5979e+13  2e+13  1e-10  1e+03\n",
      " 4:  4.2492e+03 -1.5979e+11  2e+11  7e-11  1e+01\n",
      " 5: -1.5664e+02 -1.5979e+09  2e+09  1e-12  1e-01\n",
      " 6: -1.5708e+02 -1.5979e+07  2e+07  1e-14  1e-03\n",
      " 7: -1.5708e+02 -1.5995e+05  2e+05  4e-15  1e-05\n",
      " 8: -1.5708e+02 -1.7550e+03  2e+03  1e-15  1e-07\n",
      " 9: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-09\n",
      "10: -1.5708e+02 -1.5724e+02  2e-01  5e-15  1e-11\n",
      "11: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-13\n",
      "12: -1.5708e+02 -1.5708e+02  2e-05  1e-14  1e-15\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "99.70238095238095\n",
      "Testing Accuracy\n",
      "87.83783783783784\n",
      "Valid Accuracy\n",
      "82.3529411764706\n",
      "----------------------------------------------------------------\n",
      "s = 10.0 c = 10^0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5696e+02 -1.6916e+02  6e+02  1e+00  2e+00\n",
      " 1: -1.1497e+02 -2.0277e+02  9e+01  1e-14  2e-16\n",
      " 2: -1.4801e+02 -1.5891e+02  1e+01  1e-14  2e-16\n",
      " 3: -1.5220e+02 -1.5260e+02  4e-01  4e-15  9e-17\n",
      " 4: -1.5236e+02 -1.5236e+02  4e-03  4e-15  8e-17\n",
      " 5: -1.5236e+02 -1.5236e+02  4e-05  6e-15  7e-17\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.0782e+03 -1.9855e+03  5e+03  4e-14  8e+00\n",
      " 1:  1.3239e+01 -5.4460e+02  6e+02  9e-14  1e+00\n",
      " 2: -1.5707e+02 -1.7498e+02  2e+01  3e-14  2e-02\n",
      " 3: -1.5708e+02 -1.5726e+02  2e-01  4e-15  2e-04\n",
      " 4: -1.5708e+02 -1.5708e+02  2e-03  1e-14  2e-06\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-05  4e-16  2e-08\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9016e+05  2.0973e+04  4e+05  6e-13  8e+01\n",
      " 1:  3.4497e+03 -1.2867e+05  1e+05  6e-13  1e+01\n",
      " 2: -1.5650e+02 -1.7543e+03  2e+03  5e-13  1e-01\n",
      " 3: -1.5708e+02 -1.7307e+02  2e+01  6e-15  1e-03\n",
      " 4: -1.5708e+02 -1.5724e+02  2e-01  2e-16  1e-05\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-03  3e-15  1e-07\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-05  3e-15  1e-09\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^3\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9734e+07  4.3627e+06  4e+07  7e-12  8e+02\n",
      " 1:  2.6252e+05 -1.3813e+07  1e+07  6e-12  1e+02\n",
      " 2: -1.1164e+02 -1.5972e+05  2e+05  4e-12  1e+00\n",
      " 3: -1.5707e+02 -1.7542e+03  2e+03  7e-15  1e-02\n",
      " 4: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-04\n",
      " 5: -1.5708e+02 -1.5724e+02  2e-01  5e-15  1e-06\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-03  2e-15  1e-08\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-05  6e-15  1e-10\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^4\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9804e+09  4.5899e+08  4e+09  4e-11  8e+03\n",
      " 1:  2.5351e+07 -1.3909e+09  1e+09  9e-11  1e+03\n",
      " 2:  4.2627e+03 -1.5963e+07  2e+07  2e-12  1e+01\n",
      " 3: -1.5663e+02 -1.5994e+05  2e+05  5e-14  1e-01\n",
      " 4: -1.5708e+02 -1.7549e+03  2e+03  4e-15  1e-03\n",
      " 5: -1.5708e+02 -1.7305e+02  2e+01  2e-16  1e-05\n",
      " 6: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-07\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-03  6e-15  1e-09\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^5\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+11  4.6127e+10  4e+11  4e-11  8e+04\n",
      " 1:  2.5260e+09 -1.3918e+11  1e+11  3e-10  1e+04\n",
      " 2:  4.4057e+05 -1.5964e+09  2e+09  1e-10  1e+02\n",
      " 3: -1.1300e+02 -1.5979e+07  2e+07  6e-12  1e+00\n",
      " 4: -1.5707e+02 -1.5995e+05  2e+05  7e-14  1e-02\n",
      " 5: -1.5708e+02 -1.7550e+03  2e+03  7e-16  1e-04\n",
      " 6: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-06\n",
      " 7: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-08\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-03  2e-16  1e-10\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-12\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^6\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+13  4.6149e+12  4e+13  1e-08  8e+05\n",
      " 1:  2.5251e+11 -1.3919e+13  1e+13  1e-08  1e+05\n",
      " 2:  4.4060e+07 -1.5964e+11  2e+11  7e-09  1e+03\n",
      " 3:  4.2494e+03 -1.5979e+09  2e+09  1e-10  1e+01\n",
      " 4: -1.5664e+02 -1.5979e+07  2e+07  2e-12  1e-01\n",
      " 5: -1.5708e+02 -1.5995e+05  2e+05  5e-15  1e-03\n",
      " 6: -1.5708e+02 -1.7550e+03  2e+03  2e-14  1e-05\n",
      " 7: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-07\n",
      " 8: -1.5708e+02 -1.5724e+02  2e-01  9e-15  1e-09\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-11\n",
      "10: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-13\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^7\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+15  4.6152e+14  4e+15  1e-07  8e+06\n",
      " 1:  2.5250e+13 -1.3920e+15  1e+15  5e-08  1e+06\n",
      " 2:  4.4059e+09 -1.5964e+13  2e+13  4e-08  1e+04\n",
      " 3:  4.4048e+05 -1.5979e+11  2e+11  1e-09  1e+02\n",
      " 4: -1.1301e+02 -1.5979e+09  2e+09  8e-12  1e+00\n",
      " 5: -1.5707e+02 -1.5979e+07  2e+07  7e-14  1e-02\n",
      " 6: -1.5708e+02 -1.5995e+05  2e+05  2e-15  1e-04\n",
      " 7: -1.5708e+02 -1.7550e+03  2e+03  2e-16  1e-06\n",
      " 8: -1.5708e+02 -1.7305e+02  2e+01  2e-15  1e-08\n",
      " 9: -1.5708e+02 -1.5724e+02  2e-01  2e-15  1e-10\n",
      "10: -1.5708e+02 -1.5708e+02  2e-03  7e-15  1e-12\n",
      "11: -1.5708e+02 -1.5708e+02  2e-05  1e-14  1e-14\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "s = 10.0 c = 10^8\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+17  4.6152e+16  4e+17  2e-07  8e+07\n",
      " 1:  2.5250e+15 -1.3920e+17  1e+17  1e-06  1e+07\n",
      " 2:  4.4059e+11 -1.5964e+15  2e+15  1e-07  1e+05\n",
      " 3:  4.4063e+07 -1.5979e+13  2e+13  1e-10  1e+03\n",
      " 4:  4.2492e+03 -1.5979e+11  2e+11  7e-11  1e+01\n",
      " 5: -1.5664e+02 -1.5979e+09  2e+09  5e-13  1e-01\n",
      " 6: -1.5708e+02 -1.5979e+07  2e+07  2e-15  1e-03\n",
      " 7: -1.5708e+02 -1.5995e+05  2e+05  6e-15  1e-05\n",
      " 8: -1.5708e+02 -1.7550e+03  2e+03  3e-15  1e-07\n",
      " 9: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-09\n",
      "10: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-11\n",
      "11: -1.5708e+02 -1.5708e+02  2e-03  1e-14  1e-13\n",
      "12: -1.5708e+02 -1.5708e+02  2e-05  2e-14  1e-15\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "89.58333333333333\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "89.41176470588235\n",
      "----------------------------------------------------------------\n",
      "s = 100.0 c = 10^0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5696e+02 -1.6916e+02  6e+02  1e+00  2e+00\n",
      " 1: -1.1497e+02 -2.0277e+02  9e+01  6e-15  2e-16\n",
      " 2: -1.4801e+02 -1.5891e+02  1e+01  4e-15  1e-16\n",
      " 3: -1.5220e+02 -1.5260e+02  4e-01  9e-16  9e-17\n",
      " 4: -1.5236e+02 -1.5236e+02  4e-03  5e-15  7e-17\n",
      " 5: -1.5236e+02 -1.5236e+02  4e-05  6e-15  7e-17\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.0782e+03 -1.9855e+03  5e+03  4e-14  8e+00\n",
      " 1:  1.3239e+01 -5.4460e+02  6e+02  1e-14  1e+00\n",
      " 2: -1.5707e+02 -1.7498e+02  2e+01  2e-14  2e-02\n",
      " 3: -1.5708e+02 -1.5726e+02  2e-01  3e-15  2e-04\n",
      " 4: -1.5708e+02 -1.5708e+02  2e-03  1e-14  2e-06\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-05  1e-15  2e-08\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9016e+05  2.0973e+04  4e+05  6e-13  8e+01\n",
      " 1:  3.4497e+03 -1.2867e+05  1e+05  1e-13  1e+01\n",
      " 2: -1.5650e+02 -1.7543e+03  2e+03  5e-13  1e-01\n",
      " 3: -1.5708e+02 -1.7307e+02  2e+01  7e-15  1e-03\n",
      " 4: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-05\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-07\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-09\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^3\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9734e+07  4.3627e+06  4e+07  7e-12  8e+02\n",
      " 1:  2.6252e+05 -1.3813e+07  1e+07  6e-12  1e+02\n",
      " 2: -1.1164e+02 -1.5972e+05  2e+05  4e-12  1e+00\n",
      " 3: -1.5707e+02 -1.7542e+03  2e+03  7e-15  1e-02\n",
      " 4: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-04\n",
      " 5: -1.5708e+02 -1.5724e+02  2e-01  5e-15  1e-06\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-03  2e-15  1e-08\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-05  6e-15  1e-10\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^4\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9804e+09  4.5899e+08  4e+09  4e-11  8e+03\n",
      " 1:  2.5351e+07 -1.3909e+09  1e+09  9e-11  1e+03\n",
      " 2:  4.2627e+03 -1.5963e+07  2e+07  2e-12  1e+01\n",
      " 3: -1.5663e+02 -1.5994e+05  2e+05  6e-14  1e-01\n",
      " 4: -1.5708e+02 -1.7549e+03  2e+03  3e-15  1e-03\n",
      " 5: -1.5708e+02 -1.7305e+02  2e+01  6e-15  1e-05\n",
      " 6: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-07\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-03  1e-14  1e-09\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-05  6e-15  1e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^5\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+11  4.6127e+10  4e+11  4e-11  8e+04\n",
      " 1:  2.5260e+09 -1.3918e+11  1e+11  3e-10  1e+04\n",
      " 2:  4.4057e+05 -1.5964e+09  2e+09  1e-10  1e+02\n",
      " 3: -1.1300e+02 -1.5979e+07  2e+07  6e-12  1e+00\n",
      " 4: -1.5707e+02 -1.5995e+05  2e+05  7e-14  1e-02\n",
      " 5: -1.5708e+02 -1.7550e+03  2e+03  7e-16  1e-04\n",
      " 6: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-06\n",
      " 7: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-08\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-03  2e-16  1e-10\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-12\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^6\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+13  4.6149e+12  4e+13  1e-08  8e+05\n",
      " 1:  2.5251e+11 -1.3919e+13  1e+13  1e-08  1e+05\n",
      " 2:  4.4060e+07 -1.5964e+11  2e+11  7e-09  1e+03\n",
      " 3:  4.2494e+03 -1.5979e+09  2e+09  1e-10  1e+01\n",
      " 4: -1.5664e+02 -1.5979e+07  2e+07  2e-12  1e-01\n",
      " 5: -1.5708e+02 -1.5995e+05  2e+05  3e-14  1e-03\n",
      " 6: -1.5708e+02 -1.7550e+03  2e+03  4e-15  1e-05\n",
      " 7: -1.5708e+02 -1.7305e+02  2e+01  9e-15  1e-07\n",
      " 8: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-09\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-03  9e-16  1e-11\n",
      "10: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-13\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^7\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+15  4.6152e+14  4e+15  1e-07  8e+06\n",
      " 1:  2.5250e+13 -1.3920e+15  1e+15  5e-08  1e+06\n",
      " 2:  4.4059e+09 -1.5964e+13  2e+13  4e-08  1e+04\n",
      " 3:  4.4048e+05 -1.5979e+11  2e+11  1e-09  1e+02\n",
      " 4: -1.1301e+02 -1.5979e+09  2e+09  8e-12  1e+00\n",
      " 5: -1.5707e+02 -1.5979e+07  2e+07  1e-13  1e-02\n",
      " 6: -1.5708e+02 -1.5995e+05  2e+05  4e-15  1e-04\n",
      " 7: -1.5708e+02 -1.7550e+03  2e+03  2e-15  1e-06\n",
      " 8: -1.5708e+02 -1.7305e+02  2e+01  7e-15  1e-08\n",
      " 9: -1.5708e+02 -1.5724e+02  2e-01  3e-15  1e-10\n",
      "10: -1.5708e+02 -1.5708e+02  2e-03  6e-15  1e-12\n",
      "11: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-14\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "s = 100.0 c = 10^8\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+17  4.6152e+16  4e+17  2e-07  8e+07\n",
      " 1:  2.5250e+15 -1.3920e+17  1e+17  1e-06  1e+07\n",
      " 2:  4.4059e+11 -1.5964e+15  2e+15  1e-07  1e+05\n",
      " 3:  4.4063e+07 -1.5979e+13  2e+13  1e-10  1e+03\n",
      " 4:  4.2492e+03 -1.5979e+11  2e+11  7e-11  1e+01\n",
      " 5: -1.5664e+02 -1.5979e+09  2e+09  5e-13  1e-01\n",
      " 6: -1.5708e+02 -1.5979e+07  2e+07  2e-15  1e-03\n",
      " 7: -1.5708e+02 -1.5995e+05  2e+05  6e-15  1e-05\n",
      " 8: -1.5708e+02 -1.7550e+03  2e+03  3e-15  1e-07\n",
      " 9: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-09\n",
      "10: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-11\n",
      "11: -1.5708e+02 -1.5708e+02  2e-03  1e-14  1e-13\n",
      "12: -1.5708e+02 -1.5708e+02  2e-05  2e-14  1e-15\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "86.30952380952381\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "87.05882352941177\n",
      "----------------------------------------------------------------\n",
      "s = 1000.0 c = 10^0\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5696e+02 -1.6916e+02  6e+02  1e+00  2e+00\n",
      " 1: -1.1497e+02 -2.0277e+02  9e+01  6e-15  2e-16\n",
      " 2: -1.4801e+02 -1.5891e+02  1e+01  4e-15  1e-16\n",
      " 3: -1.5220e+02 -1.5260e+02  4e-01  9e-16  9e-17\n",
      " 4: -1.5236e+02 -1.5236e+02  4e-03  5e-15  7e-17\n",
      " 5: -1.5236e+02 -1.5236e+02  4e-05  6e-15  7e-17\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "83.03571428571429\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^1\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.0782e+03 -1.9855e+03  5e+03  4e-14  8e+00\n",
      " 1:  1.3239e+01 -5.4460e+02  6e+02  9e-14  1e+00\n",
      " 2: -1.5707e+02 -1.7498e+02  2e+01  3e-14  2e-02\n",
      " 3: -1.5708e+02 -1.5726e+02  2e-01  4e-15  2e-04\n",
      " 4: -1.5708e+02 -1.5708e+02  2e-03  1e-14  2e-06\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-05  4e-16  2e-08\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9016e+05  2.0973e+04  4e+05  6e-13  8e+01\n",
      " 1:  3.4497e+03 -1.2867e+05  1e+05  1e-13  1e+01\n",
      " 2: -1.5650e+02 -1.7543e+03  2e+03  5e-13  1e-01\n",
      " 3: -1.5708e+02 -1.7307e+02  2e+01  7e-15  1e-03\n",
      " 4: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-05\n",
      " 5: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-07\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-09\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^3\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9734e+07  4.3627e+06  4e+07  7e-12  8e+02\n",
      " 1:  2.6252e+05 -1.3813e+07  1e+07  6e-12  1e+02\n",
      " 2: -1.1164e+02 -1.5972e+05  2e+05  4e-12  1e+00\n",
      " 3: -1.5707e+02 -1.7542e+03  2e+03  4e-14  1e-02\n",
      " 4: -1.5708e+02 -1.7305e+02  2e+01  1e-15  1e-04\n",
      " 5: -1.5708e+02 -1.5724e+02  2e-01  2e-16  1e-06\n",
      " 6: -1.5708e+02 -1.5708e+02  2e-03  1e-15  1e-08\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-10\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^4\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9804e+09  4.5899e+08  4e+09  4e-11  8e+03\n",
      " 1:  2.5351e+07 -1.3909e+09  1e+09  9e-11  1e+03\n",
      " 2:  4.2627e+03 -1.5963e+07  2e+07  2e-12  1e+01\n",
      " 3: -1.5663e+02 -1.5994e+05  2e+05  5e-14  1e-01\n",
      " 4: -1.5708e+02 -1.7549e+03  2e+03  4e-15  1e-03\n",
      " 5: -1.5708e+02 -1.7305e+02  2e+01  2e-16  1e-05\n",
      " 6: -1.5708e+02 -1.5724e+02  2e-01  1e-14  1e-07\n",
      " 7: -1.5708e+02 -1.5708e+02  2e-03  6e-15  1e-09\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-05  4e-15  1e-11\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^5\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+11  4.6127e+10  4e+11  4e-11  8e+04\n",
      " 1:  2.5260e+09 -1.3918e+11  1e+11  3e-10  1e+04\n",
      " 2:  4.4057e+05 -1.5964e+09  2e+09  1e-10  1e+02\n",
      " 3: -1.1300e+02 -1.5979e+07  2e+07  6e-12  1e+00\n",
      " 4: -1.5707e+02 -1.5995e+05  2e+05  4e-14  1e-02\n",
      " 5: -1.5708e+02 -1.7550e+03  2e+03  7e-15  1e-04\n",
      " 6: -1.5708e+02 -1.7305e+02  2e+01  4e-15  1e-06\n",
      " 7: -1.5708e+02 -1.5724e+02  2e-01  2e-15  1e-08\n",
      " 8: -1.5708e+02 -1.5708e+02  2e-03  5e-15  1e-10\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-05  6e-15  1e-12\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^6\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+13  4.6149e+12  4e+13  1e-08  8e+05\n",
      " 1:  2.5251e+11 -1.3919e+13  1e+13  1e-08  1e+05\n",
      " 2:  4.4060e+07 -1.5964e+11  2e+11  7e-09  1e+03\n",
      " 3:  4.2494e+03 -1.5979e+09  2e+09  1e-10  1e+01\n",
      " 4: -1.5664e+02 -1.5979e+07  2e+07  2e-12  1e-01\n",
      " 5: -1.5708e+02 -1.5995e+05  2e+05  5e-15  1e-03\n",
      " 6: -1.5708e+02 -1.7550e+03  2e+03  2e-14  1e-05\n",
      " 7: -1.5708e+02 -1.7305e+02  2e+01  5e-15  1e-07\n",
      " 8: -1.5708e+02 -1.5724e+02  2e-01  9e-15  1e-09\n",
      " 9: -1.5708e+02 -1.5708e+02  2e-03  4e-15  1e-11\n",
      "10: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-13\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^7\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+15  4.6152e+14  4e+15  1e-07  8e+06\n",
      " 1:  2.5250e+13 -1.3920e+15  1e+15  5e-08  1e+06\n",
      " 2:  4.4059e+09 -1.5964e+13  2e+13  4e-08  1e+04\n",
      " 3:  4.4048e+05 -1.5979e+11  2e+11  1e-09  1e+02\n",
      " 4: -1.1301e+02 -1.5979e+09  2e+09  8e-12  1e+00\n",
      " 5: -1.5707e+02 -1.5979e+07  2e+07  7e-14  1e-02\n",
      " 6: -1.5708e+02 -1.5995e+05  2e+05  2e-15  1e-04\n",
      " 7: -1.5708e+02 -1.7550e+03  2e+03  2e-16  1e-06\n",
      " 8: -1.5708e+02 -1.7305e+02  2e+01  2e-15  1e-08\n",
      " 9: -1.5708e+02 -1.5724e+02  2e-01  2e-15  1e-10\n",
      "10: -1.5708e+02 -1.5708e+02  2e-03  7e-15  1e-12\n",
      "11: -1.5708e+02 -1.5708e+02  2e-05  1e-14  1e-14\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "s = 1000.0 c = 10^8\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+17  4.6152e+16  4e+17  2e-07  8e+07\n",
      " 1:  2.5250e+15 -1.3920e+17  1e+17  1e-06  1e+07\n",
      " 2:  4.4059e+11 -1.5964e+15  2e+15  1e-07  1e+05\n",
      " 3:  4.4063e+07 -1.5979e+13  2e+13  1e-10  1e+03\n",
      " 4:  4.2492e+03 -1.5979e+11  2e+11  7e-11  1e+01\n",
      " 5: -1.5664e+02 -1.5979e+09  2e+09  5e-13  1e-01\n",
      " 6: -1.5708e+02 -1.5979e+07  2e+07  2e-15  1e-03\n",
      " 7: -1.5708e+02 -1.5995e+05  2e+05  6e-15  1e-05\n",
      " 8: -1.5708e+02 -1.7550e+03  2e+03  3e-15  1e-07\n",
      " 9: -1.5708e+02 -1.7305e+02  2e+01  1e-14  1e-09\n",
      "10: -1.5708e+02 -1.5724e+02  2e-01  6e-15  1e-11\n",
      "11: -1.5708e+02 -1.5708e+02  2e-03  1e-14  1e-13\n",
      "12: -1.5708e+02 -1.5708e+02  2e-05  2e-14  1e-15\n",
      "Optimal solution found.\n",
      "Training Accuracy\n",
      "82.73809523809524\n",
      "Testing Accuracy\n",
      "90.54054054054055\n",
      "Valid Accuracy\n",
      "85.88235294117646\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "train_x , train_y = load_data(\"wdbc_train.data\")\n",
    "test_x  , test_y  = load_data(\"wdbc_test.data\")\n",
    "valid_x , valid_y = load_data(\"wdbc_valid.data\")\n",
    "s = np.array([0.1,1,10,100,1000])\n",
    "c = np.array([0,1,2,3,4,5,6,7,8])\n",
    "for s0 in s:\n",
    "#     c0 = pow(10,i)\n",
    "    for i in c:\n",
    "        c0 = pow(10,i)\n",
    "        print(\"s = \"+str(s0)+\" c = 10^\"+str(i))\n",
    "        # Training\n",
    "        alpha = SVM_dual(\"wdbc_train.data\",s0,c0)\n",
    "        k =  gausian_k(train_x,train_x,s0)\n",
    "#         train_w = np.dot(train_x.T,alpha * train_y)\n",
    "        f_train = np.dot(k.T,(alpha * train_y))\n",
    "#         train_b = np.sum(train_y - f) / train_y.shape[0]\n",
    "        f_train[f_train < 0] = -1\n",
    "        f_train[f_train > 0] = 1\n",
    "        print(\"Training Accuracy\")\n",
    "        print(100*np.count_nonzero(f_train * train_y + 1) / train_y.shape[0])\n",
    "        #Testing\n",
    "        k_test = gausian_k(train_x,test_x,s0)\n",
    "        f_test = np.dot(k_test.T,(alpha * train_y))\n",
    "        # f_test = np.dot(test_x,train_w) + train_b\n",
    "        f_test[f_test < 0 ] = -1\n",
    "        f_test[f_test > 0 ] = 1\n",
    "        print(\"Testing Accuracy\")\n",
    "        print(100*np.count_nonzero(f_test * test_y + 1) / test_y.shape[0])\n",
    "        \n",
    "        #Valid\n",
    "        k_valid = gausian_k(train_x,valid_x,s0)\n",
    "        f_valid = np.dot(k_valid.T,(alpha * train_y))\n",
    "        # f_test = np.dot(test_x,train_w) + train_b\n",
    "        f_valid[f_valid < 0 ] = -1\n",
    "        f_valid[f_valid > 0 ] = 1\n",
    "        print(\"Valid Accuracy\")\n",
    "        print(100*np.count_nonzero(f_valid * valid_y + 1) / valid_y.shape[0])\n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.9812e+15  4.6152e+14  4e+15  1e-07  8e+06\n",
      " 1:  2.5250e+13 -1.3920e+15  1e+15  5e-08  1e+06\n",
      " 2:  4.4059e+09 -1.5964e+13  2e+13  4e-08  1e+04\n",
      " 3:  4.4048e+05 -1.5979e+11  2e+11  1e-09  1e+02\n",
      " 4: -1.1301e+02 -1.5979e+09  2e+09  8e-12  1e+00\n",
      " 5: -1.5707e+02 -1.5979e+07  2e+07  1e-13  1e-02\n",
      " 6: -1.5708e+02 -1.5995e+05  2e+05  4e-15  1e-04\n",
      " 7: -1.5708e+02 -1.7550e+03  2e+03  2e-15  1e-06\n",
      " 8: -1.5708e+02 -1.7305e+02  2e+01  7e-15  1e-08\n",
      " 9: -1.5708e+02 -1.5724e+02  2e-01  3e-15  1e-10\n",
      "10: -1.5708e+02 -1.5708e+02  2e-03  6e-15  1e-12\n",
      "11: -1.5708e+02 -1.5708e+02  2e-05  9e-15  1e-14\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "#Load data and configure\n",
    "s = 1\n",
    "c = 10000000\n",
    "train_x , train_y = load_data(\"wdbc_train.data\")\n",
    "alpha = SVM_dual(\"wdbc_train.data\",s,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate w and b \n",
    "k =  kernel_gau(train_x,s)\n",
    "train_w = np.dot(train_x.T,alpha * train_y)\n",
    "f = np.dot(k.T,(alpha * train_y))\n",
    "num_data = train_y.shape[0]\n",
    "train_b = np.sum(train_y - f) / num_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970238095238095"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing on train set\n",
    "f[f < 0 ] = -1\n",
    "f[f > 0 ] = 1\n",
    "num_data = train_y.shape[0]\n",
    "np.count_nonzero(f * train_y + 1) / num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783783783783784"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing on test set\n",
    "test_x,test_y = load_data(\"wdbc_test.data\")\n",
    "k_test = gausian_k(train_x,test_x,1)\n",
    "\n",
    "f_test = np.dot(k_test.T,(alpha * train_y))\n",
    "# f_test = np.dot(test_x,train_w) + train_b\n",
    "f_test[f_test < 0 ] = -1\n",
    "f_test[f_test > 0 ] = 1\n",
    "num_data = test_y.shape[0]\n",
    "np.count_nonzero(f_test * test_y + 1) / num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array([[1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x-y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 9],\n",
       "       [1, 4, 9]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.94065646e-324,   9.88131292e-324],\n",
       "       [  1.97626258e-323,   2.47032823e-323]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.00673795],\n",
       "       [ 0.00673795,  1.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[1,1,1]])\n",
    "\n",
    "kernel_gau(x,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[1,2,3]])\n",
    "def gausian_k(x,z,s):    \n",
    "    k = np.array([]).reshape(0,z.shape[0])\n",
    "    for row_x in x:\n",
    "        temp = np.power(z-row_x,2)\n",
    "        temp = -np.sum(temp,axis=1) / (2 * s * s)\n",
    "        temp = np.exp(temp)\n",
    "        k    = np.vstack([k, temp.T]) \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.      ,  0.082085],\n",
       "       [ 0.082085,  1.      ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gausian_k(x,x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.20849986e-02],\n",
       "       [  1.38879439e-11]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "y = np.array([[1,1,1]])\n",
    "gausian_k(x,y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[1],[2]])\n",
    "y = np.array([]).reshape(0,x.shape[0])\n",
    "y = np.vstack([y, x.T])\n",
    "# np.concatenate((y,x),axis = 0)\n",
    "# for i in range(0,2):\n",
    "#     y = np.vstack([y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 148)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2215955682095021"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pairwise_dists = squareform(pdist(x, 'euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225456,)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=pdist(x, 'euclidean')\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 1)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = np.array(sol['x'])\n",
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ = np.dot(train_x.T,alpha * train_y)\n",
    "w_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ = (alpha * train_y) * train_x\n",
    "w_ = np.array([np.sum(w_,axis=0)])\n",
    "#Evaluation\n",
    "f = np.dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 336)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.70238095238095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.dot(k,(alpha * train_y))\n",
    "f[f<0]   = -1\n",
    "f[f>0]   = 1\n",
    "accuracy = 100*np.count_nonzero(train_y*f+1)/336\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "test_x,test_y = load_data(\"wdbc_test.data\")\n",
    "k = kernel_gau(test_x,1)\n",
    "f_test = np.dot(k,(alpha * test_y))\n",
    "# f[f<0]   = -1\n",
    "# f[f>0]   = 1\n",
    "# accuracy = 100*np.count_nonzero(test_y*f+1)/row_training\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 1)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 10)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 148)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = np.dot(train_x,w_.T)\n",
    "f[f<0]   = -1\n",
    "f[f>0]   = 1\n",
    "\n",
    "# accuracy = 100*np.count_nonzero(train_y*f+1)/row_training\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy as sc\n",
    "  # this is an NxD matrix, where N is number of items and D its dimensionalites\n",
    "X = train_x \n",
    "s = 1\n",
    "pairwise_dists = squareform(pdist(X, 'euclidean'))\n",
    "K = sc.exp(-pairwise_dists ** 2 / s ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 336)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 10)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.69047619047619"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.dot(k,alpha * train_y)\n",
    "f[f<0]   = -1\n",
    "f[f>0]   = 1\n",
    "accuracy = 100*np.count_nonzero(train_y*f+1)/row_training\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Final version\n",
    "import numpy as np\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "\n",
    "def load_data(filename):\n",
    "    input = np.loadtxt(filename, dtype='d', delimiter=',')\n",
    "    row_length,col_length = input.shape\n",
    "\n",
    "    row_training  = int(row_length) #336\n",
    "    training_data = input[0:row_training,0:col_length]\n",
    "\n",
    "    # Initialize training\n",
    "    train_x = input[:,1:col_length]\n",
    "    train_x = np.concatenate((train_x,np.ones((row_training,1))),axis = 1)#Add ones column as bias\n",
    "    train_y = input[:,0:1]\n",
    "    return [train_x,train_y]\n",
    "    \n",
    "def SVM_primal(filename,c):\n",
    "    # Load input\n",
    "    input = np.loadtxt(filename, dtype='d', delimiter=',')\n",
    "    row_length,col_length = input.shape\n",
    "\n",
    "    row_training  = int(row_length) #336\n",
    "    training_data = input[0:row_training,0:col_length]\n",
    "\n",
    "    # Initialize training\n",
    "    train_x = input[:,1:col_length]\n",
    "    train_x = np.concatenate((train_x,np.ones((row_training,1))),axis = 1)#Add ones column as bias\n",
    "    train_y = input[:,0:1]\n",
    "#     c = 1\n",
    "    feature_num = train_x.shape[1] #11\n",
    "\n",
    "    P = np.eye(feature_num-1)\n",
    "    P = np.concatenate((P,np.zeros((feature_num-1,row_training+1))),axis = 1)\n",
    "    P = np.concatenate((P,np.zeros((row_training+1,row_training+feature_num))),axis = 0) #347 x 347\n",
    "\n",
    "    q = c * np.concatenate((np.zeros((1,feature_num)),train_y.T),axis=1)\n",
    "\n",
    "    h = np.concatenate((-np.ones((row_training,1)),np.zeros((row_training,1))),axis=0)\n",
    "\n",
    "    x = np.concatenate((train_x,np.zeros((row_training,feature_num))),axis=0) #336 x 347\n",
    "    eye = np.eye(row_training) # 336 x 336\n",
    "    eye = np.vstack((eye,eye)) #Add ones column as bias -> already added above\n",
    "    x = np.concatenate((x,eye),axis=1) #672 x 347\n",
    "    y = np.concatenate((train_y,train_y),axis=0)\n",
    "    G = -y * x\n",
    "\n",
    "    # Quadprop for Primal\n",
    "\n",
    "    # Define QP parameters (directly)\n",
    "    P_ = matrix(P)\n",
    "    q_ = matrix(q.T)\n",
    "    G_ = matrix(G)\n",
    "    h_ = matrix(h)\n",
    "\n",
    "    # Construct the QP, invoke solver\n",
    "    sol = solvers.qp(P_,q_,G_,h_)\n",
    "\n",
    "    # Get weight and b\n",
    "    train_w = np.array(sol['x'])\n",
    "    train_w = train_w[0:feature_num]\n",
    "#     f = np.dot(train_x,train_w)\n",
    "#     f[f < 0] = -1\n",
    "#     f[f > 0] =  1 \n",
    "\n",
    "#     #print training accurary\n",
    "#     print (\"Accuracy: \"+str(100*np.count_nonzero(train_y*f+1)/row_training))\n",
    "    return train_w\n",
    "    #print Testing accurary\n",
    "\n",
    "    # np.count_nonzero(train_y*f+1)\n",
    "    \n",
    "def testing(filename,w):\n",
    "    data = load_data(filename)\n",
    "    x = data[0]\n",
    "    y = data[1]\n",
    "    row_training = y.shape[]\n",
    "    f = np.dot(x,w)\n",
    "    f[f < 0] = -1\n",
    "    f[f > 0] =  1 \n",
    "    accuracy = 100*np.count_nonzero(y*f+1)/row_training\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
