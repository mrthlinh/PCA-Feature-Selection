{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training:  76.06666666666666\n",
      "Accuracy of testing:  100.0\n",
      "Accuracy of validation:  100.0\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "#Define function\n",
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename,delimiter=',')\n",
    "    row_length,col_length = data.shape\n",
    "\n",
    "    # Initialize training\n",
    "    train_x = data[:,0:col_length-1]\n",
    "    train_y = data[:,col_length-1:col_length]\n",
    "    return [train_x,train_y]\n",
    "\n",
    "def testing(filename,join_dist_neg,join_dist_pos):\n",
    "    data = load_data(filename)\n",
    "    train_x = data[0]\n",
    "    train_y = data[1]\n",
    "    row_length = train_x.shape[0]\n",
    "    \n",
    "    p_neg = train_y[train_y == 0].shape[0] / row_length\n",
    "    p_pos = train_y[train_y == 1].shape[0] / row_length\n",
    "\n",
    "    count = 0\n",
    "    for i in range(0,row_length):\n",
    "        p_neg_i = p_neg * np.product(join_dist_neg[i,:])\n",
    "        p_pos_i = p_pos * np.product(join_dist_pos[i,:])\n",
    "        result = 1\n",
    "        if (p_neg_i >= p_pos_i):\n",
    "            result = 0\n",
    "        if (train_y[i] == result):\n",
    "            count = count + 1\n",
    "    return (100*count / row_length)\n",
    "    \n",
    "    \n",
    "# Read data\n",
    "train_file = \"spam_train.data\"\n",
    "test_file = \"spam_test.data\"\n",
    "valid_file = \"spam_validation.data\"\n",
    "data = load_data(train_file)\n",
    "train_x = data[0]\n",
    "train_y = data[1]\n",
    "row_length = train_x.shape[0]\n",
    "\n",
    "# Training / Building Gaussian distribution for each class\n",
    "X_neg = train_x[np.where(train_y==0)[0],:]\n",
    "X_pos = train_x[np.where(train_y==1)[0],:]\n",
    "\n",
    "\n",
    "# Build gaussian distribution for y = 0 using MLE\n",
    "MLE_u_neg = np.mean(X_neg,axis=0,keepdims=True)\n",
    "MLE_std_neg = np.square(X_neg - MLE_u_neg)\n",
    "MLE_std_neg = np.mean(MLE_std_neg,axis=0,keepdims=True) / (row_length-1)\n",
    "\n",
    "\n",
    "# join_dist_neg = norm.pdf(X_neg,loc = MLE_u_neg,scale = MLE_std_neg)\n",
    "join_dist_neg = norm.pdf(train_x,loc = MLE_u_neg,scale = MLE_std_neg)\n",
    "# join_dist_neg = np.product(join_dist_neg)\n",
    "\n",
    "# Build gaussian distribution for y = 1 using MLE\n",
    "MLE_u_pos = np.mean(X_pos,axis=0,keepdims=True)\n",
    "MLE_std_pos = np.square(X_pos - MLE_u_pos)\n",
    "MLE_std_pos = np.sum(MLE_std_pos,axis=0,keepdims=True) / (row_length-1)\n",
    "\n",
    "join_dist_pos = norm.pdf(train_x,loc = MLE_u_pos,scale = MLE_std_pos)\n",
    "# join_dist_pos = norm.pdf(X_pos,loc = MLE_u_pos,scale = MLE_std_pos)\n",
    "# join_dist_pos = np.product(join_dist_pos)\n",
    "\n",
    "# Predict / Testing\n",
    "print(\"Accuracy of training: \",testing(train_file,join_dist_neg,join_dist_pos))\n",
    "print(\"Accuracy of testing: \",testing(test_file,join_dist_neg,join_dist_pos))\n",
    "print(\"Accuracy of validation: \",testing(valid_file,join_dist_neg,join_dist_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 57)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_dist_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLE_u_neg = np.mean(X_neg,axis=0,keepdims=True)\n",
    "MLE_std_neg = np.square(X_neg - MLE_u_neg)\n",
    "MLE_std_neg = np.mean(MLE_std_neg,axis=0,keepdims=True) / (row_length-1)\n",
    "\n",
    "\n",
    "# join_dist_neg = norm.pdf(X_neg,loc = MLE_u_neg,scale = MLE_std_neg)\n",
    "join_dist_neg = norm.pdf(train_x,loc = MLE_u_neg,scale = MLE_std_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PCA(filename,k):\n",
    "    # Read data\n",
    "    data = load_data(filename)\n",
    "    X = data[0]\n",
    "    Y = data[1]\n",
    "    # Define input and output\n",
    "    num_data = X.shape[0]\n",
    "    num_feature = X.shape[1]\n",
    "    # Construct matrix W - sample covariance matrix \n",
    "    X_mean = np.mean(X,axis=0)\n",
    "    X_mean = np.reshape(X_mean,(num_feature,1))\n",
    "    W = X - np.dot(np.ones((num_data,1)),X_mean.T)\n",
    "    # Find SVD of W - covariance matrix\n",
    "    U, s, V = np.linalg.svd(W, full_matrices=True)\n",
    "    # eigen vectors and eigen value of covariance matrix \n",
    "    eigen_vec = U\n",
    "    # s = np.reshape(s,(s.shape[0],1))\n",
    "    # eigen_value = np.dot(s,s.T)\n",
    "    eigen_value = s * s\n",
    "    # Top k eigen value\n",
    "    print(\"Top \",k,\" eigen values: \",eigen_value[:k])\n",
    "    V_r = V[:,:k]\n",
    "    return V_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  3  eigen values:  [  1.52029434e+09   1.28884476e+08   3.44289156e+06]\n"
     ]
    }
   ],
   "source": [
    "V_r = PCA(train_file,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = list(range(1,11))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Problem 1 - section 2\n",
    "# Probability of first data point\n",
    "\n",
    "\n",
    "def dist_pi(feature,V_r,k):\n",
    "    pi = 0\n",
    "    for i in range(0,k):\n",
    "        pi = pi + np.square(V_r[feature,i])\n",
    "    return (pi / k)\n",
    "\n",
    "k_list = list(range(1,11))\n",
    "s_list = list(range(1,20))\n",
    "for k in k_list:\n",
    "    V_r = PCA(train_file,k)\n",
    "    for s in s_list:\n",
    "        \n",
    "# sum = 0\n",
    "# for i in range(0,57):\n",
    "#     sum = sum + dist_pi(i,V_r,k)\n",
    "# print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = np.ones((3000,57))\n",
    "for i in range(0,57):\n",
    "    dist[:,i] = dist_pi(i,V_r,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.43333333333333"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing(train_file,dist,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3780543061854113e-09"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_pi(0,V_r,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.37805431e-09,   1.37805431e-09,   1.37805431e-09, ...,\n",
       "         1.37805431e-09,   1.37805431e-09,   1.37805431e-09])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 57)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_dist_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_dist_neg = norm.pdf(train_x,loc = MLE_u_neg,scale = MLE_std_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = V_r * V_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(v[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.62210162e-05,  -1.72620590e-05,  -2.47331606e-04,\n",
       "        -1.34398079e-02,   2.60249982e-02,  -4.71376754e-04,\n",
       "         1.96087763e-02,  -2.90153582e-02,   1.81130966e-03,\n",
       "        -2.48387733e-03,   1.90035300e-02,  -2.12007963e-02,\n",
       "         1.74077525e-02,  -4.46678561e-03,   2.74060969e-02,\n",
       "        -1.54270453e-02,   1.92243118e-02,  -2.65109929e-02,\n",
       "        -6.49010270e-03,   7.57110978e-03,   2.46986057e-02,\n",
       "         8.31206347e-03,  -3.13907449e-02,  -4.44065827e-02,\n",
       "         1.72354710e-01,   7.37940853e-02,   3.93700960e-02,\n",
       "        -9.72146983e-04,  -3.97912537e-02,  -7.58509570e-02,\n",
       "        -1.71086787e-02,   8.79456762e-02,   2.23808846e-02,\n",
       "         2.64352746e-03,   5.65721911e-02,   4.96268755e-02,\n",
       "        -8.11395021e-02,  -2.30152468e-01,   7.43307153e-01,\n",
       "         4.62817236e-01,   2.31052625e-02,   1.05328773e-01,\n",
       "        -3.40978107e-02,  -2.64029223e-01,  -4.93390581e-02,\n",
       "         1.25041457e-01,   3.81486564e-02,   2.88680526e-02,\n",
       "         4.46831080e-02,   7.32374927e-03,  -2.49361436e-02,\n",
       "        -2.59798132e-02,  -1.08322818e-02,   9.49501556e-03,\n",
       "         5.57816416e-04,   6.01127117e-03,   5.17872405e-03])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_r[:,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
